{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import sqs_nqs_tools as nqs\n",
    "from sqs_nqs_tools.offline import access, adata, tof\n",
    "\n",
    "# Plot options\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np \n",
    "from types import MappingProxyType\n",
    "\n",
    "# Import karabo libraries\n",
    "import karabo_bridge as kb\n",
    "import karabo_data as kd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize empty dictionary object for temp storage of TOF AVG traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tof_avg_traces_temp_stor = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path ='/gpfs/exfel/exp/SQS/201802/p002195/raw'\n",
    "_samples = 16 #number of combined tof channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Load a TOF AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tof_avg(run_no, path=raw_path):\n",
    "    key = str(run_no)\n",
    "    # check if run number already available in tmp storage dictionary, if so just return it from there\n",
    "    if key in tof_avg_traces_temp_stor:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"read from HDF5 - run: \"+key)\n",
    "        [TOFtrace, TOFrange] = adata.getTOF(run_no, path=path, fullrange=True)\n",
    "        TOFavg = tof.averageTOF(TOFtrace)\n",
    "        tof_avg_traces_temp_stor[key] = {'range': TOFrange, 'trace': TOFavg}\n",
    "    # need to return copy of arrays, since otherwise temporary stored variables may be changed due to processing\n",
    "    # dicts and np arrays are mutable!!\n",
    "    return np.copy(tof_avg_traces_temp_stor[key]['range']),np.copy(tof_avg_traces_temp_stor[key]['trace'])\n",
    "    \n",
    "    \n",
    "def plot_tof_avgs(run_no_list, path=raw_path, xlim='auto', alpha=1, downsampling_to_single_digitizer=False,plt_style='-', bg=None):\n",
    "    plt.figure()\n",
    "    for run_no in run_no_list:\n",
    "        tof_range, tof_trace = get_tof_avg(run_no, path=path)\n",
    "        tof_range, tof_trace = tof_data_processing(tof_range,tof_trace,downsampling_to_single_digitizer, bg=bg)                                                            \n",
    "        plt.plot(tof_range,tof_trace,plt_style,label=str(run_no), alpha = alpha)\n",
    "    if xlim is not 'auto':\n",
    "        plt.xlim(xlim)\n",
    "    downsampling_warning_plot_title(downsampling_to_single_digitizer)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def get_integral(run_no,path=raw_path, x_range='full', downsampling_to_single_digitizer=False, bg = None):\n",
    "    tof_range, tof_trace = get_tof_avg(run_no, path=path)\n",
    "    tof_range, tof_trace = tof_data_processing(tof_range,tof_trace,downsampling_to_single_digitizer, bg=bg)                                                            \n",
    "    if x_range == 'full':\n",
    "        x_range = [np.min(tof_range), np.max(tof_range)]\n",
    "    integral_idx = (tof_range > x_range[0]) * (tof_range < x_range[1])\n",
    "    integral = np.sum(tof_trace[integral_idx])\n",
    "    return float(integral)\n",
    "\n",
    "def get_integrals(run_no_list,path=raw_path, x_ranges=['full'], downsampling_to_single_digitizer=False, bg = None):\n",
    "    integral_array = np.zeros(shape=(len(run_no_list),len(x_ranges)))\n",
    "    for idx in range(len(run_no_list)):\n",
    "        run_no = run_no_list[idx]\n",
    "        for idx_range in range(len(x_ranges)):\n",
    "            x_range = x_ranges[idx_range]\n",
    "            integral = get_integral(run_no,path=path, x_range=x_range, downsampling_to_single_digitizer=downsampling_to_single_digitizer, bg=bg )\n",
    "            integral_array[idx,idx_range] = integral\n",
    "        \n",
    "    return integral_array\n",
    "\n",
    "def plot_integral_scan(runs, x_range_list, scan_axis='runs', downsampling_to_single_digitizer=False, bg=None):\n",
    "    if scan_axis == 'runs':\n",
    "        scan_axis = runs\n",
    "        \n",
    "    integral_array = get_integrals(runs, x_ranges=x_range_list, downsampling_to_single_digitizer=downsampling_to_single_digitizer, bg=bg)\n",
    "    \n",
    "    plt.figure()\n",
    "    for i in range(integral_array.shape[1]):\n",
    "        plt.plot(scan_axis,integral_array[:,i], 'o', label=str(x_range_list[i]))\n",
    "    plt.legend()\n",
    "    downsampling_warning_plot_title(downsampling_to_single_digitizer)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def get_1d_data_downsampling_to_single_digitizer(data, bg=None, samples=_samples):\n",
    "    data_idx_selection = np.arange(0,len(data),samples)\n",
    "    data = data[data_idx_selection]\n",
    "    if bg is not None:\n",
    "        data = data - np.mean(data[int(np.floor(bg[0]/samples)):int(np.floor(bg[1]/samples))])\n",
    "    return data\n",
    "\n",
    "def get_TOF_correction_for_multi_channel_sampling(data, bg=None, samples=_samples):\n",
    "    for idx in range(samples):\n",
    "        data_idx_selection = np.arange(idx,len(data),samples)\n",
    "        data_excerpt = data[data_idx_selection]\n",
    "        if bg is not None:\n",
    "            data_excerpt = data_excerpt - np.mean(data_excerpt[int(np.floor(bg[0]/samples)):int(np.floor(bg[1]/samples))])\n",
    "        data[data_idx_selection] = data_excerpt\n",
    "    return data\n",
    "\n",
    "def downsampling_warning_str(samples=_samples):\n",
    "    return \"Plot based on every \"+str(samples)+\"th point of TOF trace data!!!\"\n",
    "def downsampling_warning_plot_title(downsampling_to_single_digitizer):\n",
    "    if downsampling_to_single_digitizer:\n",
    "        plt.title(downsampling_warning_str())\n",
    "def tof_data_processing(tof_range,tof_trace,downsampling, bg=None):\n",
    "    if downsampling:\n",
    "        tof_range=get_1d_data_downsampling_to_single_digitizer( tof_range)\n",
    "        tof_trace=get_1d_data_downsampling_to_single_digitizer( tof_trace, bg=bg )\n",
    "    else:\n",
    "        tof_trace=get_TOF_correction_for_multi_channel_sampling( tof_trace, bg=bg )\n",
    "    return tof_range,tof_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot AVG TOF Traces from various runs on top of each other:\n",
    "\n",
    "**Arguments:**<br>\n",
    "A list of runs you are interested in (eg. `[1,2,5]`) for runs 1, 2 and 5\n",
    "\n",
    "**Optional (keyword) arguments:**<br>\n",
    "* `xlim` - specify xlimits default: `'auto'`, hard limits in the format `(leftlimit, rightlimit)`<br>\n",
    "* `alpha` - specify an alpha (transparency) for overlays - default `1` (no transparency)<br>\n",
    "* `downsampling_to_single_digitizer` - default: `False`, if `True` only every 8th point is plotted, this removes artificial noise created by different offsets of contributing (8) channels, maybe also 16 depending on setting of variable `_samples`<br>\n",
    "* `bg` - option to specify range where a \"zero\" can be obtained, this way when downsampling is disabled, but `bg` is set (default: `None`) all _sample channels that have different offsets are processed such that the offset is removed <br>\n",
    "**NOTE: there shall not be any signal withing the specified bg range!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tof_avgs([101,102,103],xlim=(140000,160000),downsampling_to_single_digitizer=False,plt_style='-',  bg=[0,50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Integrals vs scan axis\n",
    "\n",
    "here we assume that a single run contains only a single scan position!\n",
    "\n",
    "**plot_integral_scan(runs, x_range_list, scan_axis='runs', downsampling_to_single_digitizer=True)**\n",
    "\n",
    "`x_range_list` - is a list of integration ranges each may is specified as `[min_x, max_x]` or `'full'`\n",
    "`runs` - A list of runs you are interested in (eg. `[1,2,5]`) for runs 1, 2 and 5\n",
    "<br><br>\n",
    "`scan_axis` - values for scan axis in the order of `runs` input parameter, or `'runs'` which makes the input for `runs` the scan axis (default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [101,102,103,105]\n",
    "dummy_scan_axis = [1,2,3,4]\n",
    "x_range_list = [[120000,140000], [144000,160000] ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_integral_scan(runs, x_range_list, scan_axis=dummy_scan_axis, downsampling_to_single_digitizer=False, bg=[0,50000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
